{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd00bd98-9b7e-4437-8518-90d25e69a00e",
   "metadata": {},
   "source": [
    "# 0-60mph ðŸƒ with CMIP6 datasets in the cloud\n",
    "\n",
    "## Learning goals\n",
    "- Searching and selecting CMIP6 datasets from the cloud catalog\n",
    "- Simple plots for multiple models\n",
    "\n",
    "## Caveats\n",
    "1. This notebook is exectuable locally\n",
    "2. This notebook does not demonstrate the use of dask for parallelism.\n",
    "3. Anonymous execution of [Pangeo gallery](http://gallery.pangeo.io/) notebooks is disabled for now due to cryptomining abuse. That means you cannot execute those notebooks but you can definitely view them.\n",
    "4. If you want to work more seriously with the data sign up to access the [pangeo cloud deployments](https://pangeo.io/cloud.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6654d130-7f65-45d5-a1bb-5f9d825133ec",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "The data are stored in the cloud.  We  do not interact with the \"files\" (or \"assets\") directly. Instead we access them through a catalog that contains all the information needed to read the data.\n",
    "\n",
    "Here we use the catalog functionality provided by [intake-esm](https://intake-esm.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb3a24-069c-4528-be06-b4e6d3722535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cmip6_preprocessing.preprocessing import combined_preprocessing\n",
    "\n",
    "\n",
    "# This file points to the Google Cloud Storage pangeo catalog\n",
    "url = \"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\"\n",
    "\n",
    "# There is a mirror on Amazon S3 (this currently still contains \n",
    "# some retracted datasets, so we currently recommend the GCS version)\n",
    "# url = \"https://cmip6-pds.s3.amazonaws.com/pangeo-cmip6.json\"\n",
    "\n",
    "col = intake.open_esm_datastore(url)\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f491f-1736-485a-8e4d-5ada6af030bb",
   "metadata": {},
   "source": [
    "What you see here is a catalog of many different [zarr](https://zarr.readthedocs.io/en/stable/) stores in the cloud (currently 515388 ðŸ˜³). \n",
    "Each of these datasets represents different models, experiments, variables and so on. These different attributes - often called 'facets' - are described by a fixed [vocabulary](https://github.com/WCRP-CMIP/CMIP6_CVs). As an example the different models are given by the `source_id` facet. You can see above that there are 88 models in the catalog.\n",
    "\n",
    ">For this demonstration we take advantage of [intake-esm](https://github.com/intake/intake-esm), which gives us this nice representation of the catalog above and some convenient search and load utilities which we demo below. \n",
    "\n",
    ">This is however purely optional. There are [multiple ways](https://pangeo-data.github.io/pangeo-cmip6-cloud/accessing_data.html) of accessing the data in the cloud, and most steps demonstrated below work with either of them.\n",
    "\n",
    "Lets see which models are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd0892-f672-4cda-8529-0124f5e6356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `.df` method exposes a pandas dataframe, which you can inspect as usual\n",
    "sorted(col.df['source_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee4f6c5-5ab4-4c81-acb4-8ac0c3f21b73",
   "metadata": {},
   "source": [
    "One rarely uses the full archive, and usually we want to search for a subset of data. \n",
    "\n",
    "We can achieve this by [searching/subsetting](https://intake-esm.readthedocs.io/en/stable/user-guide/search.html) the catalog.\n",
    "\n",
    "So for instance, if we only want to look at the historical forcing experiment, we can search for it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d617a-e4fb-47e6-a7f2-c19f50272364",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = col.search(experiment_id = 'historical')\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64dd06a-5cf7-491f-80cd-f68996693799",
   "metadata": {},
   "source": [
    "You can now see that there is in fact only one experiment left in the subset catalog.\n",
    "\n",
    "Thats still a lot of data (look at `zstore`), so lets search for several facets at the same time to get this down to a bunch of datasets we can use in the tutorial.\n",
    "\n",
    "Lets pick monthly output (`table_id='Omon'`) and the native grid (`grid_label='gn'`) for three models picked from the list above. For the example we are only going to look at the ocean salinity `variable_id='so'` variable.\n",
    "\n",
    "You can explore other variables and their CMIP names [here](https://docs.google.com/spreadsheets/d/1UUtoz6Ofyjlpx5LdqhKcwHFz2SGoTQV2_yekHyMfL9Y/edit#gid=1221485271)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6fc3e1-f629-406c-b75b-e94bf5e73adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = col.search(\n",
    "    # We are chosing only the experiments with the historical forcing\n",
    "    experiment_id = 'historical',\n",
    "    # Chose the 3d ocean salinity variable\n",
    "    variable_id='so',\n",
    "    # Monthly averages\n",
    "    table_id='Omon',\n",
    "    # On the native model grid\n",
    "    grid_label='gn',\n",
    "    # chose just three models from above as example\n",
    "    source_id=['MPI-ESM1-2-HR', 'CanESM5-CanOE', 'GFDL-ESM4']\n",
    ")\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f36b74-7813-4d42-b0d3-2b0135131b50",
   "metadata": {},
   "source": [
    "Ok time to load the datasets into a dictionary. Note that this is only 'lazily' loading the data, which means we only access the metadata, and the full output is only loaded when we perform a computation!\n",
    "\n",
    "`datasets_dict` is a dictionary mapping a long unique namelike`'CMIP.CCCma.CanESM5-CanOE.historical.r1i1p2f1.Omon.so ...` to an xarray Dataset that represent the model output.\n",
    "\n",
    "Note that this step will be a little slow if executed on your laptop; it is a lot faster in the cloud.\n",
    "\n",
    "The `preprocess` argument enables you to apply any function to each dataset. We are using the wrapper function `combined_preprocessing` here to avoid issues with different naming etc ([more info on cmip6_preprocessing](https://cmip6-preprocessing.readthedocs.io/en/latest/tutorial.html))\n",
    "\n",
    "> cmip6_preprocessing works well with intake-esm, but this function can be applied to any CMIP6 xarray dataset (e.g. loaded from local netcdfs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b711cd-ba21-49e5-8ecf-c8a1989371da",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dict = cat.to_dataset_dict(\n",
    "    zarr_kwargs={'use_cftime':True,'consolidated':True},\n",
    "    aggregate=False,\n",
    "    preprocess=combined_preprocessing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87fa021-3951-4548-85c0-34a95053f1c0",
   "metadata": {},
   "source": [
    "Here is the first dataset for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f071dd-8f2b-41fc-b8d6-5e8e469f230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(datasets_dict.values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b92998-d5f1-43f5-a04c-d3fcbdca41b6",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "Now lets do something really simple: Plot the surface salinity at the first timestep using a nice projection from [cartopy](https://scitools.org.uk/cartopy/docs/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04efa2e-946c-4129-b59b-c6bcb1ef5f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set up axes for plotting using matplotlib/cartopy \n",
    "fig, axarr = plt.subplots(\n",
    "    # 3 columns\n",
    "    ncols=3,\n",
    "    # figure size in inches\n",
    "    figsize=[14,3],\n",
    "    # projection for the plot\n",
    "    subplot_kw={'projection':ccrs.Robinson()}\n",
    ")\n",
    "\n",
    "# loop over each dataset and associated axes\n",
    "for ds, ax in zip(datasets_dict.values(), axarr.flat):\n",
    "    ds.isel(time=0, lev=0).so.plot(\n",
    "        ax=ax,\n",
    "        infer_intervals=False,\n",
    "        x='lon',\n",
    "        y='lat',\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        vmax=40,\n",
    "        vmin=10,\n",
    "        cbar_kwargs={\"orientation\": \"horizontal\", \"aspect\": 40},\n",
    "    )\n",
    "    ax.coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfff72d-bde8-4a6e-bd64-3b4142f6f176",
   "metadata": {},
   "source": [
    "Now we can select a particular box in the tropical eastern Pacific \n",
    "> Bonus points if you are able to mask out the little corner of the Gulf of Mexico with [cmip6_preprocessing](https://cmip6-preprocessing.readthedocs.io/en/latest/regionmask.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a9a08-30e8-4889-bda2-21eb1ba76699",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(\n",
    "    ncols=3,\n",
    "    figsize=[20,3],\n",
    "    subplot_kw={'projection':ccrs.PlateCarree()}\n",
    ")\n",
    "for ds, ax in zip(datasets_dict.values(), axarr.flat):\n",
    "    masked_ds = ds.where(\n",
    "        (ds.lon > 210) & (ds.lon < 300) & (ds.lat < 15) & (ds.lat > -15), drop=True\n",
    "    )\n",
    "    masked_ds.isel(time=0, lev=0).so.plot(\n",
    "        ax=ax,\n",
    "        infer_intervals=False,\n",
    "        x='lon',\n",
    "        y='lat',\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        vmax=40,\n",
    "        vmin=10,\n",
    "    )\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([masked_ds.lon.min(), masked_ds.lon.max(), -15, 15], crs=ccrs.PlateCarree())\n",
    "    ax.gridlines(draw_labels=['bottom', 'left'])\n",
    "    ax.set_aspect(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf2d8d7-fd87-4f08-92d5-8398fc490b4b",
   "metadata": {},
   "source": [
    "## Some more useful information and examples\n",
    "\n",
    "That was just a start\n",
    "- See the [Pangeo gallery](http://gallery.pangeo.io/) for more oceanography examples!\n",
    "- A blogpost about interpolating tracers to density surfaces https://medium.com/pangeo/vertical-coordinate-transformation-with-pangeo-have-some-pancakes-and-let-xgcm-do-the-work-b0056604d346\n",
    "\n",
    "## Questions?\n",
    "\n",
    "You will undoubtedly have some questions as you work through the notebook. \n",
    "\n",
    "Bring them up in the chat or at [discourse.pangeo.io](https://discourse.pangeo.io) after the session is done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tutorial_osm22_cmip6]",
   "language": "python",
   "name": "conda-env-tutorial_osm22_cmip6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
